{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPK Regulation Scraping Prototype\n",
    "\n",
    "This notebook scrapes regulation data from BPK website and updates the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPKRegulationScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://peraturan.bpk.go.id\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "    \n",
    "    def scrape_regulation_detail(self, url: str) -> Dict[str, Any]:\n",
    "        \"\"\"Scrape regulation details from BPK website\"\"\"\n",
    "        print(f\"Scraping URL: {url}\")\n",
    "        \n",
    "        response = self.session.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Initialize result dictionary\n",
    "        result = {\n",
    "            'nama_peraturan': None,\n",
    "            'link_peraturan': url,\n",
    "            'tipe_dokumen': None,\n",
    "            'materi_pokok': None,\n",
    "            'judul': None,\n",
    "            'teu': None,\n",
    "            'nomor': None,\n",
    "            'bentuk': None,\n",
    "            'bentuk_singkat': None,\n",
    "            'tahun': None,\n",
    "            'tempat_penetapan': None,\n",
    "            'tanggal_penetapan': None,\n",
    "            'tanggal_pengundangan': None,\n",
    "            'tanggal_berlaku': None,\n",
    "            'sumber': None,\n",
    "            'status': None,\n",
    "            'bahasa': None,\n",
    "            'lokasi': None,\n",
    "            'bidang': None,\n",
    "            'subjek': None,  # Add subjek field\n",
    "            'dicabut_dengan': [],\n",
    "            'mencabut': [],\n",
    "            'diubah_dengan': [],\n",
    "            'mengubah': [],\n",
    "            'ujimateri_mk': [],\n",
    "            'file_peraturan': [],\n",
    "            'file_pdf': None\n",
    "        }\n",
    "        \n",
    "        # Extract title from page header\n",
    "        title_element = soup.find('h4', class_='mb-8')\n",
    "        if title_element:\n",
    "            result['nama_peraturan'] = title_element.get_text(strip=True)\n",
    "        \n",
    "        # Extract full title/subject\n",
    "        subject_element = soup.find('h1', class_='text-white')\n",
    "        if subject_element:\n",
    "            result['materi_pokok'] = subject_element.get_text(strip=True)\n",
    "        \n",
    "        # Extract detailed information from rows\n",
    "        detail_rows = soup.find_all('div', class_=['py-4', 'bg-light-primary'])\n",
    "        \n",
    "        for row in detail_rows:\n",
    "            label_element = row.find('div', class_='fw-bold')\n",
    "            if not label_element:\n",
    "                continue\n",
    "                \n",
    "            label = label_element.get_text(strip=True)\n",
    "            value_element = label_element.find_next_sibling('div')\n",
    "            \n",
    "            if not value_element:\n",
    "                continue\n",
    "                \n",
    "            value = value_element.get_text(strip=True)\n",
    "            \n",
    "            # Map labels to fields\n",
    "            if 'Judul' in label:\n",
    "                result['judul'] = value\n",
    "            elif 'Nomor' in label:\n",
    "                result['nomor'] = value\n",
    "            elif 'Tahun' in label:\n",
    "                result['tahun'] = value\n",
    "            elif 'Tempat Penetapan' in label:\n",
    "                result['tempat_penetapan'] = value\n",
    "            elif 'Tanggal Penetapan' in label:\n",
    "                result['tanggal_penetapan'] = self._parse_date(value)\n",
    "            elif 'Tanggal Pengundangan' in label:\n",
    "                result['tanggal_pengundangan'] = self._parse_date(value)\n",
    "            elif 'Tanggal Berlaku' in label:\n",
    "                result['tanggal_berlaku'] = self._parse_date(value)\n",
    "            elif 'Sumber' in label:\n",
    "                result['sumber'] = value\n",
    "            elif 'Status' in label:\n",
    "                result['status'] = value\n",
    "            elif 'Bahasa' in label:\n",
    "                result['bahasa'] = value\n",
    "            elif 'Subjek' in label:\n",
    "                result['subjek'] = value if value else None\n",
    "            elif 'Bidang' in label:\n",
    "                result['bidang'] = value if value else None\n",
    "        \n",
    "        # Extract regulation type from nama_peraturan\n",
    "        if result['nama_peraturan']:\n",
    "            # Extract type like \"Peraturan Pemerintah (PP)\"\n",
    "            type_match = re.search(r'^([^N]+)(?=\\s+Nomor|\\s+No\\.)', result['nama_peraturan'])\n",
    "            if type_match:\n",
    "                result['tipe_dokumen'] = type_match.group(1).strip()\n",
    "                result['bentuk'] = result['tipe_dokumen']\n",
    "                \n",
    "                # Extract short form like \"PP\"\n",
    "                short_match = re.search(r'\\(([^)]+)\\)', result['tipe_dokumen'])\n",
    "                if short_match:\n",
    "                    result['bentuk_singkat'] = short_match.group(1)\n",
    "        \n",
    "        # Set default values\n",
    "        result['teu'] = 'Indonesia, Pemerintah Pusat'\n",
    "        result['lokasi'] = 'Pemerintah Pusat'\n",
    "        \n",
    "        # Extract PDF download link\n",
    "        pdf_links = soup.find_all('a', class_='download-file')\n",
    "        if len(pdf_links) >= 2:\n",
    "            pdf_link = pdf_links[1]  # Second occurrence\n",
    "            if pdf_link and pdf_link.get('href'):\n",
    "                result['file_pdf'] = self.base_url + pdf_link['href']\n",
    "        \n",
    "        # Extract relationships (mencabut, diubah_dengan, etc.)\n",
    "        self._extract_relationships(soup, result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _parse_date(self, date_text: str) -> Optional[str]:\n",
    "        \"\"\"Parse date from various formats\"\"\"\n",
    "        if not date_text or date_text.strip() == '':\n",
    "            return None\n",
    "            \n",
    "        # Clean the text\n",
    "        date_text = date_text.strip()\n",
    "        \n",
    "        # Try to extract date patterns\n",
    "        date_patterns = [\n",
    "            r'(\\d{1,2})\\s+(\\w+)\\s+(\\d{4})',  # 30 Juni 1961\n",
    "            r'(\\d{4})-(\\d{2})-(\\d{2})',      # 1961-06-30\n",
    "            r'(\\d{1,2})/(\\d{1,2})/(\\d{4})',  # 30/06/1961\n",
    "        ]\n",
    "        \n",
    "        month_mapping = {\n",
    "            'januari': '01', 'februari': '02', 'maret': '03', 'april': '04',\n",
    "            'mei': '05', 'juni': '06', 'juli': '07', 'agustus': '08',\n",
    "            'september': '09', 'oktober': '10', 'november': '11', 'desember': '12'\n",
    "        }\n",
    "        \n",
    "        # Pattern 1: Indonesian date format\n",
    "        match = re.search(date_patterns[0], date_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            day, month_name, year = match.groups()\n",
    "            month_num = month_mapping.get(month_name.lower())\n",
    "            if month_num:\n",
    "                return f\"{year}-{month_num}-{day.zfill(2)}\"\n",
    "        \n",
    "        # Pattern 2: ISO format\n",
    "        match = re.search(date_patterns[1], date_text)\n",
    "        if match:\n",
    "            return date_text\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_relationships(self, soup: BeautifulSoup, result: Dict[str, Any]):\n",
    "        \"\"\"Extract regulation relationships (mencabut, diubah_dengan, etc.)\"\"\"\n",
    "        \n",
    "        # Look for containers with fs-6 class (relationship sections)\n",
    "        containers = soup.find_all('div', class_='container')\n",
    "        \n",
    "        for container in containers:\n",
    "            if 'fs-6' not in container.get('class', []):\n",
    "                continue\n",
    "                \n",
    "            # Find all relationship sections within this container\n",
    "            rows = container.find_all('div', class_='row')\n",
    "            \n",
    "            current_relationship_type = None\n",
    "            \n",
    "            for row in rows:\n",
    "                # Check if this row contains a relationship header\n",
    "                header_div = row.find('div', class_=['fw-semibold', 'bg-light-primary'])\n",
    "                if header_div:\n",
    "                    header_text = header_div.get_text(strip=True).lower()\n",
    "                    \n",
    "                    # Determine the relationship type\n",
    "                    if 'diubah dengan' in header_text:\n",
    "                        current_relationship_type = 'diubah_dengan'\n",
    "                    elif 'mencabut' in header_text:\n",
    "                        current_relationship_type = 'mencabut'\n",
    "                    elif 'mengubah' in header_text:\n",
    "                        current_relationship_type = 'mengubah'\n",
    "                    elif 'dicabut dengan' in header_text:\n",
    "                        current_relationship_type = 'dicabut_dengan'\n",
    "                    else:\n",
    "                        current_relationship_type = None\n",
    "                    continue\n",
    "                \n",
    "                # Check if this row contains the actual list data\n",
    "                if current_relationship_type:\n",
    "                    ol_element = row.find('ol')\n",
    "                    if ol_element:\n",
    "                        items = []\n",
    "                        for li in ol_element.find_all('li'):\n",
    "                            link = li.find('a')\n",
    "                            if link:\n",
    "                                # Get the full text and clean it\n",
    "                                full_text = li.get_text(strip=True)\n",
    "                                \n",
    "                                # Clean up whitespace but preserve structure\n",
    "                                full_text = re.sub(r'\\s+', ' ', full_text)\n",
    "                                \n",
    "                                # Get the link and make it absolute\n",
    "                                href = link.get('href', '')\n",
    "                                if href.startswith('/'):\n",
    "                                    href = self.base_url + href\n",
    "                                \n",
    "                                items.append({\n",
    "                                    'text': full_text,\n",
    "                                    'link': href\n",
    "                                })\n",
    "                        \n",
    "                        if items:\n",
    "                            result[current_relationship_type] = items\n",
    "                        \n",
    "                        # Reset the relationship type after processing\n",
    "                        current_relationship_type = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping...\n",
      "Scraping URL: https://peraturan.bpk.go.id/Details/49482/pp-no-34-tahun-2005\n",
      "\n",
      "=== SCRAPED DATA ===\n",
      "nama_peraturan: Peraturan Pemerintah (PP) No. 34 Tahun 2005\n",
      "link_peraturan: https://peraturan.bpk.go.id/Details/49482/pp-no-34-tahun-2005\n",
      "tipe_dokumen: Peraturan Pemerintah (PP)\n",
      "materi_pokok: Perubahan Atas Peraturan Pemerintah Nomor 35 Tahun 2004 Tentang Kegiatan Usaha Hulu Minyak Dan Gas Bumi\n",
      "judul: Peraturan Pemerintah (PP)  Nomor 34 Tahun 2005 tentang Perubahan Atas Peraturan Pemerintah Nomor 35 Tahun 2004 Tentang Kegiatan Usaha Hulu Minyak Dan Gas Bumi\n",
      "teu: Indonesia, Pemerintah Pusat\n",
      "nomor: 34\n",
      "bentuk: Peraturan Pemerintah (PP)\n",
      "bentuk_singkat: PP\n",
      "tahun: 2005\n",
      "tempat_penetapan: Jakarta\n",
      "tanggal_penetapan: 2005-09-10\n",
      "tanggal_pengundangan: 2005-09-10\n",
      "tanggal_berlaku: 2005-09-10\n",
      "sumber: LN. 2005 No. 81, TLN No.  4530, LL SETNEG : 4 HLM\n",
      "status: Berlaku\n",
      "bahasa: Bahasa Indonesia\n",
      "lokasi: Pemerintah Pusat\n",
      "bidang: (empty)\n",
      "subjek: PERTAMBANGAN MIGAS, MINERAL DAN ENERGI\n",
      "dicabut_dengan: []\n",
      "mencabut: []\n",
      "diubah_dengan: [\n",
      "  {\n",
      "    \"text\": \"PP No. 55 Tahun 2009tentangPerubahan Kedua Atas Peraturan Pemerintah Nomor 35 Tahun 2004 Tentang Kegiatan Usaha Hulu Minyak Dan Gas Bumi\",\n",
      "    \"link\": \"https://peraturan.bpk.go.id/Details/4980/pp-no-55-tahun-2009\"\n",
      "  }\n",
      "]\n",
      "mengubah: [\n",
      "  {\n",
      "    \"text\": \"PP No. 35 Tahun 2004tentangKegiatan Usaha Hulu Minyak Dan Gas Bumi\",\n",
      "    \"link\": \"https://peraturan.bpk.go.id/Details/65695/pp-no-35-tahun-2004\"\n",
      "  }\n",
      "]\n",
      "ujimateri_mk: []\n",
      "file_peraturan: []\n",
      "file_pdf: https://peraturan.bpk.go.id/Download/38761/PP%20NO%2034%20TH%202005.pdf\n"
     ]
    }
   ],
   "source": [
    "# Test the scraper\n",
    "test_url = \"https://peraturan.bpk.go.id/Details/49482/pp-no-34-tahun-2005\"\n",
    "\n",
    "scraper = BPKRegulationScraper()\n",
    "\n",
    "# Scrape the data\n",
    "print(\"Starting scraping...\")\n",
    "scraped_data = scraper.scrape_regulation_detail(test_url)\n",
    "\n",
    "# Display scraped data\n",
    "print(\"\\n=== SCRAPED DATA ===\")\n",
    "for key, value in scraped_data.items():\n",
    "    if isinstance(value, list) and len(value) > 0:\n",
    "        print(f\"{key}: {json.dumps(value, indent=2, ensure_ascii=False)}\")\n",
    "    elif value is not None and value != '':\n",
    "        print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key}: (empty)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
